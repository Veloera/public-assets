{
  "afm-4.5b": 3.125,
  "aion-1.0": 2,
  "aion-1.0-mini": 2,
  "aion-rp-llama-3.1-8b": 1,
  "anubis-70b-v1.1": 1.538461538462,
  "chatgpt-4o-latest": 3,
  "claude-3-haiku": 5,
  "claude-3-opus": 5,
  "claude-3.5-haiku": 5,
  "claude-3.5-haiku-20241022": 5,
  "claude-3.5-sonnet": 5,
  "claude-3.5-sonnet-20240620": 5,
  "claude-3.7-sonnet": 5,
  "claude-3.7-sonnet:thinking": 5,
  "claude-haiku-4.5": 5,
  "claude-opus-4": 5,
  "claude-opus-4.1": 5,
  "claude-sonnet-4": 5,
  "claude-sonnet-4.5": 5,
  "codellama-7b-instruct-solidity": 1.5,
  "coder-large": 1.6,
  "codestral-2501": 3,
  "codestral-2508": 3,
  "codex-mini": 4,
  "cogito-v2-preview-deepseek-671b": 1,
  "cogito-v2-preview-llama-109b-moe": 3.277777777778,
  "cogito-v2-preview-llama-405b": 1,
  "cogito-v2-preview-llama-70b": 1,
  "command-a": 4,
  "command-r-08-2024": 4,
  "command-r-plus-08-2024": 4,
  "command-r7b-12-2024": 4,
  "cydonia-24b-v4.1": 1.666666666667,
  "deepcoder-14b-preview": 1,
  "deephermes-3-mistral-24b-preview": 3.933333333333,
  "deepseek-chat": 4,
  "deepseek-chat-v3-0324": 3.5,
  "deepseek-chat-v3.1": 4,
  "deepseek-prover-v2": 4.36,
  "deepseek-r1": 4,
  "deepseek-r1-0528": 4.375,
  "deepseek-r1-0528-qwen3-8b": 5,
  "deepseek-r1-distill-llama-70b": 4.333333333333,
  "deepseek-r1-distill-qwen-14b": 1,
  "deepseek-r1-distill-qwen-32b": 1,
  "deepseek-r1t-chimera": 4,
  "deepseek-r1t2-chimera": 4,
  "deepseek-v3.1-terminus": 3.913043478261,
  "deepseek-v3.1-terminus:exacto": 3.703703703704,
  "deepseek-v3.2-exp": 1.481481481481,
  "devstral-medium": 5,
  "devstral-small": 4,
  "devstral-small-2505": 2,
  "ernie-4.5-21b-a3b": 4,
  "ernie-4.5-21b-a3b-thinking": 4,
  "ernie-4.5-300b-a47b": 3.928571428571,
  "ernie-4.5-vl-28b-a3b": 4,
  "ernie-4.5-vl-424b-a47b": 2.97619047619,
  "gemini-2.0-flash-001": 4,
  "gemini-2.0-flash-lite-001": 4,
  "gemini-2.5-flash": 8.333333333333,
  "gemini-2.5-flash-image": 8.333333333333,
  "gemini-2.5-flash-image-preview": 8.333333333333,
  "gemini-2.5-flash-lite": 4,
  "gemini-2.5-flash-lite-preview-06-17": 4,
  "gemini-2.5-flash-lite-preview-09-2025": 4,
  "gemini-2.5-flash-preview-09-2025": 8.333333333333,
  "gemini-2.5-pro": 8,
  "gemini-2.5-pro-preview": 8,
  "gemini-2.5-pro-preview-05-06": 8,
  "gemma-2-27b-it": 1,
  "gemma-2-9b-it": 3,
  "gemma-3-12b-it": 3.333333333333,
  "gemma-3-27b-it": 1.777777777778,
  "gemma-3-4b-it": 4.001944789585,
  "gemma-3n-e4b-it": 2,
  "glm-4-32b": 1,
  "glm-4.1v-9b-thinking": 3.942857142857,
  "glm-4.5": 4.285714285714,
  "glm-4.5-air": 6.538461538462,
  "glm-4.5v": 3,
  "glm-4.6": 4.375,
  "glm-4.6:exacto": 3.666666666667,
  "goliath-120b": 1.333333333333,
  "gpt-3.5-turbo": 3,
  "gpt-3.5-turbo-0613": 2,
  "gpt-3.5-turbo-16k": 1.333333333333,
  "gpt-3.5-turbo-instruct": 1.333333333333,
  "gpt-4": 2,
  "gpt-4-0314": 2,
  "gpt-4-1106-preview": 3,
  "gpt-4-turbo": 3,
  "gpt-4-turbo-preview": 3,
  "gpt-4.1": 4,
  "gpt-4.1-mini": 4,
  "gpt-4.1-nano": 4,
  "gpt-4o": 4,
  "gpt-4o-2024-05-13": 3,
  "gpt-4o-2024-08-06": 4,
  "gpt-4o-2024-11-20": 4,
  "gpt-4o-audio-preview": 4,
  "gpt-4o-mini": 4,
  "gpt-4o-mini-2024-07-18": 4,
  "gpt-4o-mini-search-preview": 4,
  "gpt-4o-search-preview": 4,
  "gpt-4o:extended": 3,
  "gpt-5": 8,
  "gpt-5-chat": 8,
  "gpt-5-codex": 8,
  "gpt-5-image": 1,
  "gpt-5-image-mini": 0.8,
  "gpt-5-mini": 8,
  "gpt-5-nano": 8,
  "gpt-5-pro": 8,
  "gpt-5.1": 8,
  "gpt-5.1-chat": 8,
  "gpt-5.1-codex": 8,
  "gpt-5.1-codex-mini": 4,
  "gpt-oss-120b:exacto": 4.8,
  "gpt-oss-20b": 4.666666666667,
  "gpt-oss-safeguard-20b": 4,
  "granite-4.0-h-micro": 6.470588235294,
  "grok-3": 5,
  "grok-3-beta": 5,
  "grok-3-mini": 1.666666666667,
  "grok-3-mini-beta": 1.666666666667,
  "grok-4": 5,
  "grok-4-fast": 2.5,
  "grok-code-fast-1": 7.5,
  "hermes-2-pro-llama-3-8b": 3.2,
  "hermes-3-llama-3.1-405b": 1,
  "hermes-3-llama-3.1-70b": 1,
  "hermes-4-405b": 4,
  "hermes-4-70b": 3.454545454545,
  "hunyuan-a13b-instruct": 4.071428571429,
  "inflection-3-pi": 4,
  "inflection-3-productivity": 4,
  "internvl3-78b": 3.714285714286,
  "jamba-large-1.7": 4,
  "jamba-mini-1.7": 2,
  "kimi-dev-72b": 3.965517241379,
  "kimi-k2": 4.8,
  "kimi-k2-0905": 4.871794871795,
  "kimi-k2-0905:exacto": 4.166666666667,
  "kimi-k2-thinking": 4.090909090909,
  "kimi-linear-48b-a3b-instruct": 2,
  "l3-euryale-70b": 1,
  "l3-lunaris-8b": 1.25,
  "l3.1-70b-hanami-x1": 1,
  "l3.1-euryale-70b": 1.153846153846,
  "l3.3-euryale-70b": 1.153846153846,
  "lfm-2.2-6b": 2,
  "lfm2-8b-a1b": 2,
  "ling-1t": 4,
  "llama-3-70b-instruct": 1.333333333333,
  "llama-3-8b-instruct": 2,
  "llama-3.1-405b": 1,
  "llama-3.1-405b-instruct": 1,
  "llama-3.1-70b-instruct": 1,
  "llama-3.1-8b-instruct": 1.5,
  "llama-3.1-lumimaid-8b": 6.666666666667,
  "llama-3.1-nemotron-70b-instruct": 1,
  "llama-3.1-nemotron-ultra-253b-v1": 3,
  "llama-3.2-11b-vision-instruct": 1,
  "llama-3.2-1b-instruct": 7.407407407407,
  "llama-3.2-3b-instruct": 1,
  "llama-3.2-90b-vision-instruct": 1.142857142857,
  "llama-3.3-70b-instruct": 2.923076923077,
  "llama-3.3-nemotron-super-49b-v1.5": 4,
  "llama-4-maverick": 4,
  "llama-4-scout": 3.75,
  "llama-guard-2-8b": 1,
  "llama-guard-3-8b": 3,
  "llama-guard-4-12b": 1,
  "llemma_7b": 1.5,
  "longcat-flash-chat": 5,
  "maestro-reasoning": 3.666666666667,
  "magistral-medium-2506": 2.5,
  "magistral-medium-2506:thinking": 2.5,
  "magistral-small-2506": 3,
  "magnum-v4-72b": 1.666666666667,
  "mai-ds-r1": 4,
  "mercury": 4,
  "mercury-coder": 4,
  "minimax-01": 5.5,
  "minimax-m1": 5.5,
  "minimax-m2": 4,
  "ministral-3b": 1,
  "ministral-8b": 1,
  "mistral-7b-instruct": 1.928571428571,
  "mistral-7b-instruct-v0.1": 1.727272727273,
  "mistral-7b-instruct-v0.2": 1,
  "mistral-7b-instruct-v0.3": 1,
  "mistral-large": 3,
  "mistral-large-2407": 3,
  "mistral-large-2411": 3,
  "mistral-medium-3": 5,
  "mistral-medium-3.1": 5,
  "mistral-nemo": 2,
  "mistral-saba": 3,
  "mistral-small": 3,
  "mistral-small-24b-instruct-2501": 1.6,
  "mistral-small-3.1-24b-instruct": 4.4,
  "mistral-small-3.2-24b-instruct": 3,
  "mistral-tiny": 1,
  "mixtral-8x22b-instruct": 3,
  "mixtral-8x7b-instruct": 1,
  "morph-v3-fast": 1.5,
  "morph-v3-large": 2.111111111111,
  "mythomax-l2-13b": 1,
  "nemotron-nano-12b-v2-vl": 3,
  "nemotron-nano-9b-v2": 4,
  "noromaid-20b": 1.75,
  "nova-lite-v1": 4,
  "nova-micro-v1": 4,
  "nova-premier-v1": 5,
  "nova-pro-v1": 4,
  "o1": 4,
  "o1-pro": 4,
  "o3": 4,
  "o3-deep-research": 4,
  "o3-mini": 4,
  "o3-mini-high": 4,
  "o3-pro": 4,
  "o4-mini": 4,
  "o4-mini-deep-research": 4,
  "o4-mini-high": 4,
  "olmo-2-0325-32b-instruct": 1.75,
  "phi-3-medium-128k-instruct": 1,
  "phi-3-mini-128k-instruct": 1,
  "phi-3.5-mini-128k-instruct": 1,
  "phi-4": 2.333333333333,
  "phi-4-multimodal-instruct": 2,
  "phi-4-reasoning-plus": 5,
  "pixtral-12b": 1,
  "pixtral-large-2411": 3,
  "qwen-2.5-72b-instruct": 3.714285714286,
  "qwen-2.5-7b-instruct": 2.5,
  "qwen-2.5-coder-32b-instruct": 4,
  "qwen-2.5-vl-7b-instruct": 1,
  "qwen-max": 4,
  "qwen-plus": 3,
  "qwen-plus-2025-07-28": 3,
  "qwen-plus-2025-07-28:thinking": 10,
  "qwen-turbo": 4,
  "qwen-vl-max": 4,
  "qwen-vl-plus": 3,
  "qwen2.5-coder-7b-instruct": 3,
  "qwen2.5-vl-32b-instruct": 4.4,
  "qwen2.5-vl-72b-instruct": 4.125,
  "qwen3-14b": 4.4,
  "qwen3-235b-a22b": 3,
  "qwen3-235b-a22b-2507": 6.875,
  "qwen3-235b-a22b-thinking-2507": 5.454545454545,
  "qwen3-30b-a3b": 3.666666666667,
  "qwen3-30b-a3b-instruct-2507": 4.125,
  "qwen3-30b-a3b-thinking-2507": 3.333333333333,
  "qwen3-32b": 4,
  "qwen3-8b": 3.942857142857,
  "qwen3-coder": 4.318181818182,
  "qwen3-coder-30b-a3b-instruct": 4.166666666667,
  "qwen3-coder-flash": 5,
  "qwen3-coder-plus": 5,
  "qwen3-coder:exacto": 4.026315789474,
  "qwen3-max": 5,
  "qwen3-next-80b-a3b-instruct": 8,
  "qwen3-next-80b-a3b-thinking": 8,
  "qwen3-vl-235b-a22b-instruct": 4,
  "qwen3-vl-235b-a22b-thinking": 4,
  "qwen3-vl-30b-a3b-instruct": 4,
  "qwen3-vl-30b-a3b-thinking": 5,
  "qwen3-vl-8b-instruct": 6.25,
  "qwen3-vl-8b-thinking": 11.666666666667,
  "qwq-32b": 2.666666666667,
  "qwq-32b-arliai-rpr-v1": 3.666666666667,
  "relace-apply-3": 1.470588235294,
  "remm-slerp-l2-13b": 1.444444444444,
  "ring-1t": 4,
  "rocinante-12b": 2.529411764706,
  "skyfall-36b-v2": 1.6,
  "sonar": 1,
  "sonar-deep-research": 4,
  "sonar-pro": 5,
  "sonar-pro-search": 5,
  "sonar-reasoning": 5,
  "sonar-reasoning-pro": 4,
  "sorcererlm-8x22b": 1,
  "spotlight": 1,
  "step3": 2.491228070175,
  "tongyi-deepresearch-30b-a3b": 4.444444444444,
  "ui-tars-1.5-7b": 2,
  "unslopnemo-12b": 1,
  "virtuoso-large": 1.6,
  "voxtral-small-24b-2507": 3,
  "weaver": 1,
  "wizardlm-2-8x22b": 1
}
